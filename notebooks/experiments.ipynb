{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5d11ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fab4186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1855b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f53fc85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<groq.resources.chat.completions.Completions object at 0x00000157EA18F020> async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000157EA18F8A0> model_name='qwen/qwen3-32b' model_kwargs={} groq_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"qwen/qwen3-32b\",temperature=0.7)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4ab01cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Connection error.\n",
      "Please check your internet connection, API key, and Groq API status.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\tresult = model.invoke(\"What is the capital of France?\").content\n",
    "\tprint(result)\n",
    "except Exception as e:\n",
    "\tprint(f\"Error: {e}\")\n",
    "\tprint(\"Please check your internet connection, API key, and Groq API status.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0afac7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='mistral'\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "ollama_chat_model = ChatOllama(model=\"mistral\")\n",
    "print(ollama_chat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac2f0eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "print(ollama_chat_model.invoke(\"What is the capital of France?\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aadf895f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_url='http://localhost:11434' model='nomic-embed-text' embed_instruction='passage: ' query_instruction='query: ' mirostat=None mirostat_eta=None mirostat_tau=None num_ctx=None num_gpu=None num_thread=None repeat_last_n=None repeat_penalty=None temperature=None stop=None tfs_z=None top_k=None top_p=None show_progress=False headers=None model_kwargs=None\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embedding_model = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "print(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a632f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = embedding_model.embed_query('What is the capital of France?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e472d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(len(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2affc4",
   "metadata": {},
   "source": [
    "1. Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66d0d506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cceb16a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Suel.Abbasi\\Desktop\\agentic ai and RAG\\Krish Nair\\document_portal\\notebooks\\data\\sample.pdf\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "file_path = Path(os.path.join(os.getcwd(), 'data', 'sample.pdf'))\n",
    "print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "df0e484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(file_path)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8032915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c2ac75bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, \n",
    "                    chunk_overlap=150,  # experimental value, there is not deterministic way\n",
    "                    length_function=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d298c447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765\n"
     ]
    }
   ],
   "source": [
    "docs = text_splitter.split_documents(documents)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "046d9bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2: Open Foundation and Fine-Tuned Chat Models\\nHugo Touvron∗ Louis Martin† Kevin Stone†\\nPeter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\\nPrajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\nGuillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\\nCynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\\nHakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478eb1c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
